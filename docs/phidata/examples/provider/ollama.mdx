---
title: Ollama
---

## Example

<CodeGroup>

```python agent.py
from phi.agent import Agent, RunResponse
from phi.model.ollama import Ollama

agent = Agent(
    model=Ollama(id="llama3.1")
)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story.")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

</CodeGroup>

## Usage

Install [ollama](https://ollama.com) and run a model.

<Steps>

  <Step title="  Run your chat model">

  ```bash
  ollama run llama3.1
  ```

  Message `/bye` to exit the chat model

  </Step>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">

    ```bash
    pip install -U ollama phidata
    ```

  </Step>

  <Step title="Run Ollama Agent">

    ```bash
    python cookbook/providers/ollama/basic.py
    ```

  </Step>

  </Steps>

## Information

- View on [Github](https://github.com/phidatahq/phidata/tree/main/cookbook/providers/ollama/basic.py)
